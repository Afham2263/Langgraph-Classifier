LangGraph Sentiment Classifier

A robust and self-healing text classification system built with LangGraph, fine-tuned transformers, and fallback logic to ensure accurate and reliable sentiment prediction.

ğŸ¯ Objective

This project classifies text (e.g., movie reviews) as either POSITIVE or NEGATIVE using a fine-tuned DistilBERT model. When prediction confidence is low, it triggers a fallback strategy to recover gracefully using either user clarification or a backup model.

ğŸ› ï¸ Features

âœ… Fine-tuned transformer model for sentiment classification

ğŸ” LangGraph DAG with conditional fallback logic

ğŸ” Confidence-based prediction acceptance or clarification

ğŸ§  Optional zero-shot fallback model

ğŸ§¾ CLI interface for human-in-the-loop review

ğŸ“Š Logging-ready design for tracking model decisions (expandable)

ğŸ“ Project Structure

langgraph_classifier/
â”œâ”€â”€ classifier_graph.py       # LangGraph DAG and node logic
â”œâ”€â”€ cli_interface.py          # User CLI for interaction
â”œâ”€â”€ train_model.py            # Fine-tuning script
â”œâ”€â”€ load_data.py              # Dataset loading & preprocessing
â”œâ”€â”€ requirements.txt          # Dependencies
â”œâ”€â”€ .gitignore                # Ignores large and unnecessary files
â””â”€â”€ README.md                 # You are here

ğŸ“¦ Installation

git clone https://github.com/<your-username>/Langgraph-Classifier.git
cd Langgraph-Classifier
python -m venv env
source env/bin/activate  # On Windows: .\env\Scripts\activate
pip install -r requirements.txt

ğŸš€ Usage

ğŸ”§ Model Setup

The trained model isn't pushed to GitHub due to size. Download it from:

ğŸ”— Google Drive Model Folder

Unzip it and place the folder as ./model in the project directory.

ğŸ§ª Run CLI Classifier

python cli_interface.py

You'll be greeted with:

ğŸ¤– Welcome to the LangGraph Classifier CLI!
> This movie was awful

If confidence is low, you'll be prompted for clarification:

ğŸ¤” Confidence is low. Let's clarify before deciding.
Did you mean this to be a POSITIVE or NEGATIVE statement?

ğŸ§  How It Works

ğŸ”„ DAG Flow

[Input Text] â†’ InferenceNode
       â†³ High Confidence â†’ âœ… END
       â†³ Low Confidence â†’ FallbackNode (user clarification)
                                  â†³ END

InferenceNode: Runs classification using fine-tuned DistilBERT.

ConfidenceCheck: Inline conditional logic (threshold = 0.6).

FallbackNode: Prompts user to confirm sentiment manually.

ğŸ‹ï¸ Model Training

Want to train your own? Run:

python train_model.py

This script fine-tunes DistilBERT using the IMDb dataset via HuggingFace Datasets, with LoRA for parameter-efficient training.

ğŸ“œ Requirements

Install dependencies from requirements.txt. Key packages include:

transformers
peft
langgraph
accelerate
torch
scikit-learn

ğŸ“¹ Demo

ğŸ§ª CLI + fallback logic showcased in:
demo.mp4 (or add a YouTube link)

ğŸ“š References

LangGraph Docs

Hugging Face Transformers

LoRA Paper

ğŸ‘¨â€ğŸ’» Author
by Afham

ğŸ“œ License

MIT License. 
