

# ğŸ’¥ LangGraph Classifier: Confidence-Driven Text Classification with Fallback

**A self-healing NLP pipeline that doesn't just guess â€” it checks itself before it wrecks itself.**

---

## ğŸ“Œ Overview

This project is a **LangGraph-powered text classification system** designed to prioritize **correctness** over blind automation.

* ğŸ” Fine-tuned DistilBERT model for sentiment analysis
* ğŸ§  Confidence-check mechanism using LangGraph DAG
* ğŸ›¡ï¸ Fallback strategies: **zero-shot classifier** or **manual user clarification**
* ğŸ–¥ï¸ Clean CLI interface with **explainable predictions**
* ğŸ“Š Logging for decisions, confidence, and fallback tracking

---

## ğŸ› ï¸ Features

* âœ… **Transformer fine-tuning (LoRA)** on a sentiment dataset
* ğŸ§© **Modular LangGraph DAG** with custom nodes:

  * `InferenceNode`: Makes the prediction
  * `ConfidenceCheck`: Decides if prediction is confident enough
  * `FallbackNode`: Asks for clarification or uses zero-shot
* ğŸ§µ **CLI Loop** for interaction with user
* ğŸ“ˆ **Logging system** for predictions, fallback use, and confidence scores
* ğŸ§  Smart defaults but totally hackable

---

## ğŸš€ Quickstart

### ğŸ”§ Installation

```bash
git clone https://github.com/<your-username>/Langgraph-Classifier.git
cd Langgraph-Classifier
pip install -r requirements.txt
```

---

### ğŸ’¾ Model Setup

Since GitHub hates large files, download the fine-tuned model from here:

ğŸ‘‰ [Download Fine-tuned DistilBERT (Google Drive)](https://drive.google.com/drive/folders/1Pc0qavHOBYGJQhymgKH1B1txiql4u7KE)

After downloading, **extract the model into the root folder** like this:

```
Langgraph-Classifier/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ pytorch_model.bin
â”‚   â”œâ”€â”€ tokenizer.json
â”‚   â””â”€â”€ ...
```

---

### âš™ï¸ Run the Classifier

```bash
python cli_interface.py
```

You'll see:

```
ğŸ¤– Welcome to the LangGraph Classifier CLI!
Type a sentence to classify (or type 'exit' to quit):
```

Example:

```
> This movie was painfully slow and boring.

ğŸ” Classifying input text...
[InferenceNode] Predicted label: Positive | Confidence: 0.52
[ConfidenceCheckNode] Confidence too low. Triggering fallback...
[FallbackNode] Did you mean this to be a POSITIVE or NEGATIVE statement?
User: Negative
Final Label: Negative âœ…
```

---

## ğŸ§¬ LangGraph DAG Design

Here's how the pipeline flows:

```mermaid
graph TD
    A[User Input] --> B[InferenceNode]
    B -->|High Confidence| D[End]
    B -->|Low Confidence| C[FallbackNode]
    C --> D
```

---

## ğŸ“ Project Structure

```
Langgraph-Classifier/
â”œâ”€â”€ classifier_graph.py     # LangGraph DAG + Nodes
â”œâ”€â”€ cli_interface.py        # CLI loop
â”œâ”€â”€ train_model.py          # Fine-tune DistilBERT using LoRA
â”œâ”€â”€ load_data.py            # Dataset prep
â”œâ”€â”€ logs/                   # Prediction + fallback logs
â”œâ”€â”€ model/                  # (Ignored by git)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“œ Logging Output

Every prediction is logged with:

* Timestamp
* Input sentence
* Predicted label
* Confidence score
* Whether fallback was used

Logs live in `/logs/classification_log.txt`

---

## ğŸ“¹ Demo Video (Optional)

> Coming soon... (Drop your YouTube or Drive demo link here)

---

## ğŸ“£ Credits

* âš™ï¸ Built by [Afham2263](https://github.com/Afham2263)
* ğŸ§  Powered by ğŸ¤— Hugging Face + ğŸ§± LangGraph + ğŸ PyTorch
* ğŸ¯ Inspired by real-world fallback strategies in production ML pipelines

---

## ğŸ¤ License

MIT. Use, remix, and build something cooler.


